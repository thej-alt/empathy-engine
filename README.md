# The Empathy Engine ðŸŽ™ï¸

The Empathy Engine is an AI-powered Text-to-Speech (TTS) service that generates emotionally expressive speech from text.  
Unlike traditional robotic TTS systems, this service detects the **emotion and intensity** of the input text and dynamically modulates vocal characteristics to produce more human-like audio output.

---

## ðŸš€ Features

- Emotion detection from text using sentiment analysis
- Supported emotions:
  - Excited
  - Happy
  - Neutral
  - Concerned
  - Frustrated
- Emotion intensity scaling
- Dynamic voice modulation:
  - Speech rate
  - Pitch
  - Volume
- Generates playable `.wav` audio output
- REST API built using FastAPI
- Interactive API documentation via Swagger UI

---

## ðŸ› ï¸ Tech Stack

- **Python**
- **FastAPI** â€“ API framework
- **NLTK (VADER)** â€“ sentiment & emotion detection
- **pyttsx3** â€“ offline Text-to-Speech engine
- **Uvicorn** â€“ ASGI server

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/thej-alt/empathy-engine.git
cd empathy-engine
```
### 2ï¸âƒ£ Create and activate virtual environment
```bash
python -m venv venv
```
### Windows:
```bash
venv\Scripts\activate
```
###3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```
###4ï¸âƒ£ Run the application
```bash
uvicorn app.main:app --reload
```
###5ï¸âƒ£ Open Swagger UI

Open your browser and go to:
```bash
http://127.0.0.1:8000/docs
```

---

##ðŸ“¡ API Usage
POST /synthesize

###Request Body :
```json
{
  "text": "This is absolutely amazing news, I am very excited about it!"
}
```

###Response :
```json
{
  "emotion": "excited",
  "intensity": 0.82,
  "audio_file": "output/output.wav"
}
```
The generated audio file can be played locally from the output directory.
---

##ðŸ§  Design Choices & Emotion Mapping

Emotion Detection

VADER sentiment analysis was chosen for its speed, simplicity, and interpretability.

The compound sentiment score is used to classify emotions:
| Compound Score Range | Emotion    |
| -------------------- | ---------- |
| â‰¥ 0.8                | Excited    |
| 0.6 â€“ 0.79           | Happy      |
| -0.2 â€“ 0.2           | Neutral    |
| -0.59 â€“ -0.21        | Concerned  |
| â‰¤ -0.6               | Frustrated |

This separation allows the system to distinguish between strong excitement, general positivity, and mild concern, which is crucial for realistic voice modulation.

Intensity Scaling :

Emotion intensity is calculated as the absolute value of the compound sentiment score.

This intensity value controls how strongly voice parameters are modulated.

Voice Modulation Logic :

Each detected emotion maps to a predefined voice configuration :

Excited :

    Faster speech rate

    Higher pitch

    Increased volume

Happy :

    Slightly faster rate

    Moderately higher pitch

    Normal volume

Neutral :

    Default rate

    Default pitch

    Default volume

Concerned :

    Slightly slower rate

    Lower pitch

    Softer volume

Frustrated :

    Slower speech rate

    Lower pitch

    Reduced volume

This deterministic mapping ensures the system remains explainable, reproducible, and easy to extend.

---
##ðŸ”® Future Improvements:
    -> SSML-based fine-grained voice control

    -> Real-time audio streaming in API response

    -> Transformer-based emotion classification

    -> Frontend UI with embedded audio playback.
---

##ðŸ‘¤ Author

Krishna Teja Regintala
ECE Undergraduate | Machine Learning & NLP Enthusiast | DSA Practitioner
---